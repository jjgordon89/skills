#!/usr/bin/env python3
"""
ä¸“åˆ©æ£€ç´¢å·¥å…· - å¤šå¹³å°ä¸“åˆ©æ£€ç´¢
æ”¯æŒï¼šGoogle Patents, Lens.org, å¤§ä¸ºInnojoy, ç™¾åº¦å­¦æœ¯, Espacenet
"""

import argparse
import json
import re
import sys
import urllib.parse
import urllib.request
from typing import Optional
from concurrent.futures import ThreadPoolExecutor, as_completed


# ============== Google Patents ==============
def search_google_patents(query: str, limit: int = 20, country: str = "CN") -> list[dict]:
    """Google Patents æœç´¢"""
    encoded_query = urllib.parse.quote(f"{query} country:{country}")
    url = f"https://patents.google.com/xhr/query?url=q%3D{encoded_query}&num={limit}&exp="
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Accept": "application/json",
    }
    
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=30) as response:
            data = json.loads(response.read().decode("utf-8"))
            
        results = []
        if "results" in data and "cluster" in data["results"]:
            for cluster in data["results"]["cluster"]:
                if "result" in cluster:
                    for result in cluster["result"]:
                        patent = result.get("patent", {})
                        results.append({
                            "source": "Google Patents",
                            "patent_number": patent.get("publication_number", ""),
                            "title": patent.get("title", ""),
                            "abstract": patent.get("abstract", "")[:500] if patent.get("abstract") else "",
                            "assignee": patent.get("assignee", ""),
                            "filing_date": patent.get("filing_date", ""),
                            "url": f"https://patents.google.com/patent/{patent.get('publication_number', '')}"
                        })
        return results[:limit]
    except Exception as e:
        print(f"[Google Patents] æœç´¢å¤±è´¥: {e}", file=sys.stderr)
        return []


# ============== Lens.org ==============
def search_lens(query: str, limit: int = 20) -> list[dict]:
    """Lens.org æœç´¢ï¼ˆä¸“åˆ©+è®ºæ–‡ï¼‰"""
    encoded_query = urllib.parse.quote(query)
    url = f"https://www.lens.org/lens/search/patent/list?q={encoded_query}&n={limit}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Accept": "text/html,application/xhtml+xml",
    }
    
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=30) as response:
            html = response.read().decode("utf-8")
        
        # ç®€å•è§£æï¼ˆLens è¿”å› HTMLï¼‰
        results = []
        # æå–ä¸“åˆ©ä¿¡æ¯çš„æ­£åˆ™
        pattern = r'lens\.org/lens/patent/(\w+)'
        matches = re.findall(pattern, html)
        
        for lens_id in matches[:limit]:
            results.append({
                "source": "Lens.org",
                "patent_number": lens_id,
                "title": "[éœ€è®¿é—®è¯¦æƒ…é¡µ]",
                "abstract": "",
                "url": f"https://www.lens.org/lens/patent/{lens_id}"
            })
        
        if not results:
            results.append({
                "source": "Lens.org",
                "note": "å»ºè®®ç›´æ¥è®¿é—® Lens.org è¿›è¡Œæ£€ç´¢",
                "url": f"https://www.lens.org/lens/search/patent/list?q={encoded_query}"
            })
        return results
    except Exception as e:
        print(f"[Lens.org] æœç´¢å¤±è´¥: {e}", file=sys.stderr)
        return [{
            "source": "Lens.org",
            "note": f"æœç´¢å¤±è´¥: {e}",
            "url": f"https://www.lens.org/lens/search/patent/list?q={encoded_query}"
        }]


# ============== å¤§ä¸º Innojoy ==============
def search_innojoy(query: str, limit: int = 20) -> list[dict]:
    """å¤§ä¸º Innojoy ä¸“åˆ©æœç´¢"""
    encoded_query = urllib.parse.quote(query)
    # Innojoy ç®€å•æ£€ç´¢æ¥å£
    url = f"http://www.innojoy.com/search/index.html?kw={encoded_query}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Accept": "text/html,application/xhtml+xml",
    }
    
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=30) as response:
            html = response.read().decode("utf-8")
        
        results = []
        # å°è¯•è§£ææœç´¢ç»“æœ
        # Innojoy çš„ç»“æœéœ€è¦ JavaScript æ¸²æŸ“ï¼Œè¿™é‡Œè¿”å›æœç´¢é“¾æ¥
        results.append({
            "source": "å¤§ä¸ºInnojoy",
            "note": "Innojoy éœ€è¦æµè§ˆå™¨è®¿é—®ï¼Œå·²ç”Ÿæˆæœç´¢é“¾æ¥",
            "url": f"http://www.innojoy.com/search/index.html?kw={encoded_query}",
            "features": ["ä¸­å›½ä¸“åˆ©ä¸ºä¸»", "æ”¯æŒAIæ™ºèƒ½æ£€ç´¢", "å…è´¹åŸºç¡€ç‰ˆ"]
        })
        return results
    except Exception as e:
        print(f"[Innojoy] æœç´¢å¤±è´¥: {e}", file=sys.stderr)
        return [{
            "source": "å¤§ä¸ºInnojoy",
            "note": f"æœç´¢å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è®¿é—®",
            "url": f"http://www.innojoy.com/search/index.html?kw={encoded_query}"
        }]


# ============== ç™¾åº¦å­¦æœ¯ ==============
def search_baidu_xueshu(query: str, limit: int = 20) -> list[dict]:
    """ç™¾åº¦å­¦æœ¯æœç´¢ï¼ˆè®ºæ–‡+ä¸“åˆ©ï¼‰"""
    encoded_query = urllib.parse.quote(query)
    url = f"https://xueshu.baidu.com/s?wd={encoded_query}&tn=SE_baiduxueshu_c1gjeupa&ie=utf-8&sc_hit=1"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Accept": "text/html,application/xhtml+xml",
        "Accept-Language": "zh-CN,zh;q=0.9",
    }
    
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=30) as response:
            html = response.read().decode("utf-8")
        
        results = []
        # è§£æç™¾åº¦å­¦æœ¯ç»“æœ
        # æ ‡é¢˜æ¨¡å¼
        title_pattern = r'<a[^>]*class="sc_content"[^>]*>([^<]+)</a>'
        titles = re.findall(title_pattern, html)
        
        for title in titles[:limit]:
            results.append({
                "source": "ç™¾åº¦å­¦æœ¯",
                "title": title.strip(),
                "url": f"https://xueshu.baidu.com/s?wd={encoded_query}"
            })
        
        if not results:
            results.append({
                "source": "ç™¾åº¦å­¦æœ¯",
                "note": "å»ºè®®ç›´æ¥è®¿é—®ç™¾åº¦å­¦æœ¯è¿›è¡Œæ£€ç´¢",
                "url": f"https://xueshu.baidu.com/s?wd={encoded_query}",
                "features": ["è®ºæ–‡ä¸ºä¸»", "éƒ¨åˆ†ä¸“åˆ©", "ä¸­æ–‡å‹å¥½"]
            })
        return results
    except Exception as e:
        print(f"[ç™¾åº¦å­¦æœ¯] æœç´¢å¤±è´¥: {e}", file=sys.stderr)
        return [{
            "source": "ç™¾åº¦å­¦æœ¯",
            "note": f"æœç´¢å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è®¿é—®",
            "url": f"https://xueshu.baidu.com/s?wd={encoded_query}"
        }]


# ============== Espacenet (æ¬§æ´²ä¸“åˆ©å±€) ==============
def search_espacenet(query: str, limit: int = 20) -> list[dict]:
    """Espacenet æ¬§æ´²ä¸“åˆ©å±€æœç´¢"""
    encoded_query = urllib.parse.quote(query)
    url = f"https://worldwide.espacenet.com/patent/search?q={encoded_query}"
    
    # Espacenet æœ‰åçˆ¬ï¼Œè¿”å›æœç´¢é“¾æ¥
    return [{
        "source": "Espacenet",
        "note": "æ¬§æ´²ä¸“åˆ©å±€æ•°æ®åº“ï¼Œéœ€æµè§ˆå™¨è®¿é—®",
        "url": url,
        "features": ["å…¨çƒä¸“åˆ©", "æ¬§æ´²ä¸“åˆ©è¯¦ç»†", "æ”¯æŒå¤šè¯­è¨€"]
    }]


# ============== å›½çŸ¥å±€ CNIPA ==============
def search_cnipa(query: str, limit: int = 20) -> list[dict]:
    """å›½çŸ¥å±€ä¸“åˆ©æ£€ç´¢ï¼ˆéœ€ç™»å½•ï¼‰"""
    encoded_query = urllib.parse.quote(query)
    url = f"https://pss-system.cponline.cnipa.gov.cn/conventionalSearch?searchWord={encoded_query}"
    
    return [{
        "source": "å›½çŸ¥å±€CNIPA",
        "note": "å›½çŸ¥å±€å®˜æ–¹æ•°æ®åº“ï¼Œéœ€è¦ç™»å½•è´¦å·",
        "url": url,
        "register_url": "https://pss-system.cponline.cnipa.gov.cn/",
        "features": ["ä¸­å›½ä¸“åˆ©æƒå¨", "æ³•å¾‹çŠ¶æ€å‡†ç¡®", "éœ€æ³¨å†Œç™»å½•"]
    }]


# ============== ç›¸ä¼¼åº¦åˆ†æ ==============
def analyze_similarity(query: str, patents: list[dict]) -> list[dict]:
    """ç®€å•çš„ç›¸ä¼¼åº¦åˆ†æï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰"""
    keywords = set(query.lower().split())
    
    for patent in patents:
        if "note" in patent:
            continue
        title = patent.get("title", "").lower()
        abstract = patent.get("abstract", "").lower()
        content = f"{title} {abstract}"
        
        matched = sum(1 for kw in keywords if kw in content)
        patent["similarity_score"] = round(matched / len(keywords) * 100, 1) if keywords else 0
    
    return sorted(patents, key=lambda x: x.get("similarity_score", 0), reverse=True)


# ============== è¾“å‡ºæ ¼å¼åŒ– ==============
def format_output(patents: list[dict], format_type: str = "text") -> str:
    """æ ¼å¼åŒ–è¾“å‡º"""
    if format_type == "json":
        return json.dumps(patents, ensure_ascii=False, indent=2)
    
    if not patents:
        return "æœªæ‰¾åˆ°ç›¸å…³ä¸“åˆ©"
    
    lines = ["## ä¸“åˆ©æ£€ç´¢ç»“æœ\n"]
    
    # æŒ‰æ¥æºåˆ†ç»„
    sources = {}
    for p in patents:
        src = p.get("source", "æœªçŸ¥")
        if src not in sources:
            sources[src] = []
        sources[src].append(p)
    
    for source, items in sources.items():
        lines.append(f"### ğŸ“š {source}\n")
        
        for i, p in enumerate(items, 1):
            if "note" in p:
                lines.append(f"**æç¤º**: {p['note']}")
                if p.get("url"):
                    lines.append(f"ğŸ”— é“¾æ¥: {p['url']}")
                if p.get("features"):
                    lines.append(f"ç‰¹ç‚¹: {', '.join(p['features'])}")
                lines.append("")
                continue
            
            lines.append(f"**{i}. {p.get('title', 'æ— æ ‡é¢˜')}**")
            if p.get("patent_number"):
                lines.append(f"- ä¸“åˆ©å·: {p['patent_number']}")
            if p.get("assignee"):
                lines.append(f"- ç”³è¯·äºº: {p['assignee']}")
            if p.get("filing_date"):
                lines.append(f"- ç”³è¯·æ—¥: {p['filing_date']}")
            if "similarity_score" in p:
                lines.append(f"- ç›¸ä¼¼åº¦: {p['similarity_score']}%")
            if p.get("url"):
                lines.append(f"- é“¾æ¥: {p['url']}")
            if p.get("abstract"):
                lines.append(f"- æ‘˜è¦: {p['abstract'][:150]}...")
            lines.append("")
    
    return "\n".join(lines)


# ============== ä¸»å‡½æ•° ==============
def main():
    parser = argparse.ArgumentParser(
        description="å¤šå¹³å°ä¸“åˆ©æ£€ç´¢å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ•°æ®æºè¯´æ˜:
  google    - Google Patents (å…¨çƒä¸“åˆ©ï¼Œå…è´¹)
  lens      - Lens.org (ä¸“åˆ©+è®ºæ–‡ï¼Œå…è´¹)
  innojoy   - å¤§ä¸ºInnojoy (ä¸­å›½ä¸“åˆ©ï¼Œå…è´¹åŸºç¡€ç‰ˆ)
  baidu     - ç™¾åº¦å­¦æœ¯ (è®ºæ–‡+ä¸“åˆ©ï¼Œå…è´¹)
  espacenet - æ¬§æ´²ä¸“åˆ©å±€ (å…¨çƒä¸“åˆ©ï¼Œå…è´¹)
  cnipa     - å›½çŸ¥å±€ (ä¸­å›½ä¸“åˆ©ï¼Œéœ€ç™»å½•)
  all       - æ‰€æœ‰å¹³å°

ç¤ºä¾‹:
  python patent_search.py "äººå·¥æ™ºèƒ½ å›¾åƒè¯†åˆ«" -s all
  python patent_search.py "æœºå™¨å­¦ä¹ " -s google -c US -n 30
  python patent_search.py "æ·±åº¦å­¦ä¹ " -s google,lens,innojoy -a
        """
    )
    parser.add_argument("query", help="æ£€ç´¢å…³é”®è¯")
    parser.add_argument("--limit", "-n", type=int, default=20, help="æ¯ä¸ªå¹³å°è¿”å›ç»“æœæ•°é‡")
    parser.add_argument("--country", "-c", default="CN", help="å›½å®¶ä»£ç  (CN/US/EP/JP/KR)")
    parser.add_argument("--source", "-s", default="google",
                        help="æ•°æ®æºï¼Œé€—å·åˆ†éš” (google/lens/innojoy/baidu/espacenet/cnipa/all)")
    parser.add_argument("--format", "-f", choices=["text", "json"], default="text",
                        help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--analyze", "-a", action="store_true", help="è¿›è¡Œç›¸ä¼¼åº¦åˆ†æ")
    parser.add_argument("--parallel", "-p", action="store_true", help="å¹¶è¡Œæ£€ç´¢ï¼ˆæ›´å¿«ï¼‰")
    
    args = parser.parse_args()
    
    # è§£ææ•°æ®æº
    if args.source == "all":
        sources = ["google", "lens", "innojoy", "baidu", "espacenet", "cnipa"]
    else:
        sources = [s.strip().lower() for s in args.source.split(",")]
    
    # æ•°æ®æºæ˜ å°„
    search_funcs = {
        "google": lambda: search_google_patents(args.query, args.limit, args.country),
        "lens": lambda: search_lens(args.query, args.limit),
        "innojoy": lambda: search_innojoy(args.query, args.limit),
        "baidu": lambda: search_baidu_xueshu(args.query, args.limit),
        "espacenet": lambda: search_espacenet(args.query, args.limit),
        "cnipa": lambda: search_cnipa(args.query, args.limit),
    }
    
    all_results = []
    
    if args.parallel and len(sources) > 1:
        # å¹¶è¡Œæ£€ç´¢
        print(f"å¹¶è¡Œæ£€ç´¢ {len(sources)} ä¸ªå¹³å°...", file=sys.stderr)
        with ThreadPoolExecutor(max_workers=len(sources)) as executor:
            futures = {}
            for src in sources:
                if src in search_funcs:
                    futures[executor.submit(search_funcs[src])] = src
            
            for future in as_completed(futures):
                src = futures[future]
                try:
                    results = future.result()
                    all_results.extend(results)
                    print(f"[{src}] å®Œæˆï¼Œè·å– {len(results)} æ¡ç»“æœ", file=sys.stderr)
                except Exception as e:
                    print(f"[{src}] å¤±è´¥: {e}", file=sys.stderr)
    else:
        # ä¸²è¡Œæ£€ç´¢
        for src in sources:
            if src in search_funcs:
                print(f"æ­£åœ¨æœç´¢ {src}: {args.query}", file=sys.stderr)
                results = search_funcs[src]()
                all_results.extend(results)
    
    # ç›¸ä¼¼åº¦åˆ†æ
    if args.analyze and all_results:
        all_results = analyze_similarity(args.query, all_results)
    
    print(format_output(all_results, args.format))


if __name__ == "__main__":
    main()
