"""
æ¯æ—¥è®ºæ–‡é€Ÿé€’ä¸»ç¨‹åº
æ•´åˆ arXiv å’Œ HuggingFace çš„è®ºæ–‡ä¿¡æ¯
"""
import json
import os
import logging
from typing import List, Dict
from datetime import datetime
from arxiv_fetcher import ArxivFetcher
from huggingface_fetcher import HuggingFaceFetcher

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class PaperDigest:
    """è®ºæ–‡é€Ÿé€’ä¸»ç±»"""
    
    def __init__(self, config_path: str = "config/sources.json"):
        """
        åˆå§‹åŒ–è®ºæ–‡é€Ÿé€’
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.arxiv_fetcher = None
        self.hf_fetcher = None
        self._init_fetchers()
    
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
            script_dir = os.path.dirname(os.path.abspath(__file__))
            full_path = os.path.join(script_dir, config_path)
            
            with open(full_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            return config
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤é…ç½®
            return {
                "sources": [],
                "output_format": {
                    "include_abstract": True,
                    "include_authors": True,
                    "include_links": True,
                    "language": "zh-CN"
                }
            }
    
    def _init_fetchers(self):
        """åˆå§‹åŒ–å„ä¸ªä¿¡æ¯æºçš„è·å–å™¨"""
        for source in self.config.get('sources', []):
            if not source.get('enabled', False):
                continue
                
            if source['name'] == 'arxiv':
                categories = source.get('categories', ['cs.AI'])
                max_results = source.get('max_results', 10)
                self.arxiv_fetcher = ArxivFetcher(categories, max_results)
                logger.info("å·²åˆå§‹åŒ– arXiv è·å–å™¨")
                
            elif source['name'] == 'huggingface':
                max_results = source.get('max_results', 10)
                self.hf_fetcher = HuggingFaceFetcher(max_results)
                logger.info("å·²åˆå§‹åŒ– HuggingFace è·å–å™¨")
    
    def fetch_all_papers(self) -> List[Dict]:
        """
        ä»æ‰€æœ‰å¯ç”¨çš„ä¿¡æ¯æºè·å–è®ºæ–‡
        
        Returns:
            æ‰€æœ‰è®ºæ–‡çš„åˆ—è¡¨
        """
        all_papers = []
        
        # è·å– arXiv è®ºæ–‡
        if self.arxiv_fetcher:
            try:
                arxiv_papers = self.arxiv_fetcher.fetch_daily_papers()
                all_papers.extend(arxiv_papers)
                logger.info(f"ä» arXiv è·å–äº† {len(arxiv_papers)} ç¯‡è®ºæ–‡")
            except Exception as e:
                logger.error(f"è·å– arXiv è®ºæ–‡å¤±è´¥: {str(e)}")
        
        # è·å– HuggingFace è®ºæ–‡
        if self.hf_fetcher:
            try:
                hf_papers = self.hf_fetcher.fetch_daily_papers()
                all_papers.extend(hf_papers)
                logger.info(f"ä» HuggingFace è·å–äº† {len(hf_papers)} ç¯‡è®ºæ–‡")
            except Exception as e:
                logger.error(f"è·å– HuggingFace è®ºæ–‡å¤±è´¥: {str(e)}")
        
        return all_papers
    
    def filter_papers(self, papers: List[Dict]) -> List[Dict]:
        """
        æ ¹æ®é…ç½®è¿‡æ»¤è®ºæ–‡
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            
        Returns:
            è¿‡æ»¤åçš„è®ºæ–‡åˆ—è¡¨
        """
        filter_config = self.config.get('filter', {})
        keywords = filter_config.get('keywords', [])
        exclude_keywords = filter_config.get('exclude_keywords', [])
        
        if not keywords and not exclude_keywords:
            return papers
        
        filtered_papers = []
        
        for paper in papers:
            title = paper.get('title', '').lower()
            abstract = paper.get('abstract', '').lower()
            text = f"{title} {abstract}"
            
            # æ£€æŸ¥æ’é™¤å…³é”®è¯
            if exclude_keywords:
                if any(keyword.lower() in text for keyword in exclude_keywords):
                    continue
            
            # æ£€æŸ¥åŒ…å«å…³é”®è¯
            if keywords:
                if any(keyword.lower() in text for keyword in keywords):
                    filtered_papers.append(paper)
            else:
                filtered_papers.append(paper)
        
        logger.info(f"è¿‡æ»¤åå‰©ä½™ {len(filtered_papers)} ç¯‡è®ºæ–‡")
        return filtered_papers
    
    def format_paper(self, paper: Dict, index: int) -> str:
        """
        æ ¼å¼åŒ–å•ç¯‡è®ºæ–‡ä¿¡æ¯
        
        Args:
            paper: è®ºæ–‡ä¿¡æ¯
            index: åºå·
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        output_format = self.config.get('output_format', {})
        
        # æ„å»ºè¾“å‡º
        lines = []
        lines.append(f"\n{'='*60}")
        lines.append(f"ğŸ“„ è®ºæ–‡ {index}")
        lines.append(f"{'='*60}")
        lines.append(f"\nğŸ“Œ æ ‡é¢˜: {paper.get('title', 'æœªçŸ¥')}")
        
        # ä½œè€…ä¿¡æ¯
        if output_format.get('include_authors', True):
            authors = paper.get('authors', [])
            if authors:
                author_str = ', '.join(authors[:5])  # æœ€å¤šæ˜¾ç¤º5ä¸ªä½œè€…
                if len(authors) > 5:
                    author_str += f" ç­‰ {len(authors)} äºº"
                lines.append(f"ğŸ‘¥ ä½œè€…: {author_str}")
        
        # æ¥æºå’Œå‘å¸ƒæ—¥æœŸ
        source = paper.get('source', 'æœªçŸ¥').upper()
        published = paper.get('published', 'æœªçŸ¥')
        lines.append(f"ğŸ·ï¸  æ¥æº: {source} | æ—¥æœŸ: {published}")
        
        # æ‘˜è¦
        if output_format.get('include_abstract', True):
            abstract = paper.get('abstract', '')
            if abstract:
                # é™åˆ¶æ‘˜è¦é•¿åº¦
                if len(abstract) > 300:
                    abstract = abstract[:300] + '...'
                lines.append(f"\nğŸ“ æ‘˜è¦:\n{abstract}")
        
        # é“¾æ¥
        if output_format.get('include_links', True):
            if paper.get('source') == 'arxiv':
                lines.append(f"\nğŸ”— arXiv: {paper.get('arxiv_url', '')}")
                lines.append(f"ğŸ“¥ PDF: {paper.get('pdf_url', '')}")
            elif paper.get('source') == 'huggingface':
                lines.append(f"\nğŸ”— é“¾æ¥: {paper.get('url', '')}")
                likes = paper.get('likes', '0')
                lines.append(f"ğŸ‘ ç‚¹èµ: {likes}")
        
        return '\n'.join(lines)
    
    def format_digest(self, papers: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–è®ºæ–‡é€Ÿé€’æŠ¥å‘Š
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            
        Returns:
            å®Œæ•´çš„æŠ¥å‘Šæ–‡æœ¬
        """
        if not papers:
            return "ğŸ“­ ä»Šæ—¥æš‚æ— æ–°è®ºæ–‡"
        
        # æ ‡é¢˜
        title = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ“ AI è®ºæ–‡æ¯æ—¥é€Ÿé€’ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ä»Šæ—¥å…±æ”¶å½• {len(papers)} ç¯‡è®ºæ–‡

"""
        
        # æ ¼å¼åŒ–æ¯ç¯‡è®ºæ–‡
        formatted_papers = [self.format_paper(paper, i+1) for i, paper in enumerate(papers)]
        
        # ç»Ÿè®¡ä¿¡æ¯
        arxiv_count = sum(1 for p in papers if p.get('source') == 'arxiv')
        hf_count = sum(1 for p in papers if p.get('source') == 'huggingface')
        
        footer = f"""
\n{'='*60}
ğŸ“ˆ ä¿¡æ¯æºç»Ÿè®¡:
   â€¢ arXiv: {arxiv_count} ç¯‡
   â€¢ HuggingFace: {hf_count} ç¯‡

â° æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*60}
"""
        
        return title + '\n'.join(formatted_papers) + footer
    
    def run(self) -> str:
        """
        æ‰§è¡Œè®ºæ–‡é€Ÿé€’
        
        Returns:
            æ ¼å¼åŒ–åçš„æŠ¥å‘Šæ–‡æœ¬
        """
        logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥è®ºæ–‡é€Ÿé€’...")
        
        # è·å–æ‰€æœ‰è®ºæ–‡
        papers = self.fetch_all_papers()
        
        # è¿‡æ»¤è®ºæ–‡
        filtered_papers = self.filter_papers(papers)
        
        # æ ¼å¼åŒ–è¾“å‡º
        digest = self.format_digest(filtered_papers)
        
        logger.info("è®ºæ–‡é€Ÿé€’æ‰§è¡Œå®Œæˆ")
        return digest


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äº OpenClaw skill è°ƒç”¨"""
    digest = PaperDigest()
    result = digest.run()
    print(result)
    return result


if __name__ == "__main__":
    main()
